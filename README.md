# ğŸ³ Culinary RAG â€“ Easy Chinese Recipes

Assistant culinaire basÃ© sur Retrieval-Augmented Generation (RAG) qui explore le PDF `easy-chinese-recipes-pdf.pdf`, propose des recettes adaptÃ©es (vÃ©gÃ©tarien, nombre de convives, contraintes diÃ©tÃ©tiques) et affiche les sources utilisÃ©es. Le projet suit les exigences du document `Project guidelines.pdf` : pipeline RAG complet, UI Streamlit, documentation, dÃ©ploiement cloud et explication des choix techniques.

---

## 1. Architecture Globale

```
User â”€â”€ Streamlit UI (app.py)
          â”‚
          â”œâ”€ Upload / indexation PDF
          â””â”€ Questions en langage naturel
                â”‚
                â–¼
        LangChain RAG Pipeline (src/rag_pipeline.py)
          â”œâ”€ PyPDFLoader + RecursiveCharacterTextSplitter
          â”œâ”€ HuggingFace MiniLM embeddings
          â”œâ”€ Chroma (persist_directory=vectorstore/)
          â””â”€ LLM Mistral via Ollama (mode local) ou HuggingFace API (mode cloud)
```

- **Mode local (par dÃ©faut)** : Ollama + Mistral 7B, aucune dÃ©pendance cloud.
- **Mode cloud** : branche `cloud-experiments` qui active une version simplifiÃ©e du pipeline (`USE_SIMPLE_RAG=true`) et interroge HuggingFace Inference.

---

## 2. Installation Locale

### PrÃ©requis
- Python 3.10+
- Git
- [Ollama](https://ollama.ai/) + modÃ¨le `mistral`
- macOS / Linux (testÃ© sur macOS Sonoma)

### Ã‰tapes
```bash
git clone https://github.com/matthieudol/Recipies_Asian_Good.git
cd Recipies_Asian_Good/app
python -m venv .venv
source .venv/bin/activate          # Windows : .venv\Scripts\activate
pip install -r requirements.txt
ollama pull mistral

# Indexer le PDF fourni
python -m src.rag_pipeline         # enregistre les embeddings dans vectorstore/

# Lancer lâ€™interface
streamlit run app.py
```

> Lâ€™application est disponible sur `http://localhost:8501`.  
> Les dossiers `data/recipes/` et `vectorstore/` sont crÃ©Ã©s automatiquement.

---

## 3. Utilisation

1. **Indexer un PDF**  
   - via le terminal (`python -m src.rag_pipeline`)  
   - ou via la sidebar Streamlit (Upload + bouton â€œIndexer ce PDFâ€).

2. **Poser une question**  
   - ex. â€œJe veux des nouilles sautÃ©es version vÃ©gÃ©tarienne pour 6 personnesâ€.

3. **Lire la rÃ©ponse**  
   - Format imposÃ© par le prompt :  
     ```
     ğŸ“„ Document analysÃ©: easy-chinese-recipes-pdf.pdf
     âœ… Recette directe trouvÃ©e: â€¦
     Conseils pratiquesâ€¦
     ```
   - Les sources utilisÃ©es sont listÃ©es sous la rÃ©ponse.

---

## 4. Variables dâ€™Environnement

| Contexte | Variable | Description |
|----------|----------|-------------|
| Local | `EMBED_MODEL` | dÃ©faut `sentence-transformers/all-MiniLM-L6-v2` |
| Local | `OLLAMA_MODEL` | dÃ©faut `mistral` |
| Cloud | `HUGGINGFACE_API_KEY` | token HuggingFace |
| Cloud | `HUGGINGFACE_MODEL` | ex. `mistralai/Mistral-7B-Instruct-v0.2` |
| Cloud | `USE_CLOUD_LLM` | `true` pour forcer HuggingFace |
| Cloud | `USE_SIMPLE_RAG` | `true` (pipeline simplifiÃ©) |

âš ï¸ Sur Streamlit Cloud, prÃ©fÃ©rer les **Environment Variables** plutÃ´t que `secrets.toml` pour Ã©viter les erreurs de parsing. Un template est disponible dans `DEPLOYMENT.md`.

---

## 5. DÃ©ploiement Streamlit Cloud (RÃ©sumÃ©)

1. Pousser la version cloud-ready (`cloud-experiments` ou une branche dÃ©diÃ©e`).  
2. Lancer [share.streamlit.io](https://share.streamlit.io), relier le repo.  
3. ParamÃ¨tres â†’ Environment variables :  
   ```
   HUGGINGFACE_API_KEY = "hf_xxx"
   HUGGINGFACE_MODEL = "mistralai/Mistral-7B-Instruct-v0.2"
   USE_CLOUD_LLM = "true"
   USE_SIMPLE_RAG = "true"
   ```
4. `Main file path` = `app/app.py`.  
5. AprÃ¨s dÃ©ploiement, uploader `easy-chinese-recipes-pdf.pdf` via la sidebar.

Voir `DEPLOYMENT.md` pour le pas-Ã -pas dÃ©taillÃ© (captures dâ€™Ã©cran, gestion des secrets).

---

## 6. Choix Techniques vs Project Guidelines

| Exigence (guidelines.pdf) | RÃ©alisation |
|---------------------------|-------------|
| Pipeline RAG documentÃ© | README + architecture dÃ©crite ci-dessus |
| DonnÃ©es persistÃ©es localement | `vectorstore/` (Chroma) + `data/recipes/` |
| UI Streamlit ergonomique | Sidebar upload, zone de saisie, affichage des sources |
| Adaptations culinaires intelligentes | Prompt Michelin avec sorties â€œRecette directe / Adaptation possibleâ€ |
| Gestion des sources | chaque chunk conserve `metadata["source"]` |
| Documentation de dÃ©ploiement | `DEPLOYMENT.md` + section 5 de ce README |
| Bonus / idÃ©es futures | Section 8 ci-dessous |

---

## 7. DÃ©tails du Pipeline RAG

1. **Ingestion**  
   - `PyPDFLoader` â†’ pages  
   - `RecursiveCharacterTextSplitter` (1000 chars / 200 overlap)  
   - Ajout du chemin source dans `metadata["source"]`.

2. **Indexation**  
   - Embeddings via `HuggingFaceEmbeddings` (MiniLM)  
   - Stockage dans `Chroma` (persist_directory = `vectorstore/`).

3. **Retrieval + GÃ©nÃ©ration**  
   - `vectorstore.as_retriever(k=5)`  
   - `RetrievalQA.from_chain_type` avec prompt custom (`src/utils.py`)  
   - LLM = Ollama Mistral (local) ou wrapper HuggingFace API (cloud).

4. **Contraintes du prompt**  
   - Mention obligatoire â€œğŸ“„ Document analysÃ©: â€¦â€  
   - Distinction Recette directe / Adaptation possible / Aucune recette  
   - Conseils pratiques + touche fun pour rÃ©pondre aux guidelines UX.

---

## 8. AmÃ©liorations & Roadmap

- [ ] Migrer vers `langchain_huggingface` / `langchain_chroma` (versions non dÃ©prÃ©ciÃ©es).  
- [ ] Filtres diÃ©tÃ©tiques (vegan, halal, sans gluten).  
- [ ] Estimation temps de prÃ©paration + liste de courses.  
- [ ] Suggestions accords mets-vins.  
- [ ] Support multilingue (FR / EN / ES).  
- [ ] Monitoring RAG (LangFuse) + tests dâ€™intÃ©gration automatiques.  
- [ ] Mode â€œBatch indexingâ€ pour plusieurs PDFs.

---

## 9. Structure du Repo
```
RAG_Recipes/
â”œâ”€â”€ README.md                   # documentation globale
â”œâ”€â”€ Project guidelines.pdf      # cahier des charges du cours
â”œâ”€â”€ easy-chinese-recipes-pdf.pdf
â””â”€â”€ app/
    â”œâ”€â”€ app.py                  # UI Streamlit
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ rag_pipeline.py     # pipeline principal (Ollama + HuggingFace fallback)
    â”‚   â””â”€â”€ utils.py            # prompts, helpers
    â”œâ”€â”€ data/recipes/           # fichiers uploadÃ©s
    â””â”€â”€ vectorstore/            # base Chroma persistÃ©e
```

---

## 10. CrÃ©dits & Licence

- Projet acadÃ©mique rÃ©alisÃ© dans le cadre du Master 2 â€œIntroduction Ã  la GÃ©nÃ©ration dâ€™IA incluant RAGâ€.  
- PDF source : `easy-chinese-recipes-pdf.pdf` (fourni dans le repo).  
- Licence : usage Ã©ducatif uniquement.

Enjoy & bon appÃ©tit ! ğŸœ
